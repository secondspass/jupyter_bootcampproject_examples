{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1841f494-98d6-44a1-be26-a0550f7a0e1b",
   "metadata": {},
   "source": [
    "In this notebook we will explore how using multiple processors to our advantage can save time when working with large data sets. We will use the MPI for Python (mpi4py) package which provides a simple Python interface to the Message Passing Interface (MPI). MPI is designed to allow users to more easily perform distributed parallel processing across multiple processors on a single computer or even multiple nodes on an HPC system.\n",
    "\n",
    "Lets first start by loading in a power outage data set using only one processor. The code for that is below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "62fa6964-b373-469d-9d7e-677b1c9b3bf5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 12051362\n"
     ]
    }
   ],
   "source": [
    "!sbatch eagle_mpi.sbatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1392c10b-8cec-47ce-8565-8322ddb9f2af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245259387\n",
      "Done with year 2014\n",
      "1565317037\n",
      "Done with year 2015\n",
      "2064484348\n",
      "Done with year 2016\n",
      "4378327281.0\n",
      "Done with year 2017\n",
      "3296135480.0\n",
      "Done with year 2018\n",
      "2824598528.0\n",
      "Done with year 2019\n",
      "5219277476.0\n",
      "Done with year 2020\n",
      "5325390318.0\n",
      "Done with year 2021\n",
      "4441543481.0\n",
      "Done with year 2022\n",
      "The total time of the script was: 67.16525363922119 seconds\n",
      "The total blackouts from 2014-2022: 29360333336.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fips_code</th>\n",
       "      <th>county</th>\n",
       "      <th>state</th>\n",
       "      <th>sum</th>\n",
       "      <th>run_start_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1005</td>\n",
       "      <td>Barbour</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1009</td>\n",
       "      <td>Blount</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>160.0</td>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1051</td>\n",
       "      <td>Elmore</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1055</td>\n",
       "      <td>Etowah</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1057</td>\n",
       "      <td>Fayette</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22327828</th>\n",
       "      <td>72031</td>\n",
       "      <td>Carolina</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>1869.0</td>\n",
       "      <td>2022-11-12 18:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22327829</th>\n",
       "      <td>72097</td>\n",
       "      <td>Mayagüez</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>420.0</td>\n",
       "      <td>2022-11-12 18:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22327830</th>\n",
       "      <td>72113</td>\n",
       "      <td>Ponce</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>214.0</td>\n",
       "      <td>2022-11-12 18:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22327831</th>\n",
       "      <td>72127</td>\n",
       "      <td>San Juan</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2022-11-12 18:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22327832</th>\n",
       "      <td>78030</td>\n",
       "      <td>St. Thomas</td>\n",
       "      <td>United States Virgin Islands</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2022-11-12 18:30:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22327833 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          fips_code      county                         state     sum  \\\n",
       "0              1005     Barbour                       Alabama     4.0   \n",
       "1              1009      Blount                       Alabama   160.0   \n",
       "2              1051      Elmore                       Alabama     3.0   \n",
       "3              1055      Etowah                       Alabama     4.0   \n",
       "4              1057     Fayette                       Alabama     4.0   \n",
       "...             ...         ...                           ...     ...   \n",
       "22327828      72031    Carolina                   Puerto Rico  1869.0   \n",
       "22327829      72097    Mayagüez                   Puerto Rico   420.0   \n",
       "22327830      72113       Ponce                   Puerto Rico   214.0   \n",
       "22327831      72127    San Juan                   Puerto Rico     8.0   \n",
       "22327832      78030  St. Thomas  United States Virgin Islands     2.0   \n",
       "\n",
       "               run_start_time  \n",
       "0         2022-01-01 00:00:00  \n",
       "1         2022-01-01 00:00:00  \n",
       "2         2022-01-01 00:00:00  \n",
       "3         2022-01-01 00:00:00  \n",
       "4         2022-01-01 00:00:00  \n",
       "...                       ...  \n",
       "22327828  2022-11-12 18:30:00  \n",
       "22327829  2022-11-12 18:30:00  \n",
       "22327830  2022-11-12 18:30:00  \n",
       "22327831  2022-11-12 18:30:00  \n",
       "22327832  2022-11-12 18:30:00  \n",
       "\n",
       "[22327833 rows x 5 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time as tp\n",
    "\n",
    "# this line creates a variable to hold the time in which we began running the script\n",
    "t1=tp.time()\n",
    "\n",
    "# now we create a python list to hold the year of each file in the data set\n",
    "file_nums = ['2014','2015','2016','2017','2018','2019','2020','2021','2022']\n",
    "\n",
    "# we can also keep a count of the total blackouts as we read in the files using pandas\n",
    "blackouts_total = 0\n",
    "\n",
    "# this for loop iterates through each entry in our file_nums list we created above\n",
    "for i in file_nums:\n",
    "    # read the csv using pandas and assign the returned dataframe to our df variable\n",
    "    df = pd.read_csv(f'../data/eaglei_outages/eaglei_outages_{i}.csv')\n",
    "\n",
    "    # keep track of the number of blackouts in each file as we read them in\n",
    "    blackouts = df['sum']\n",
    "    blackouts_local = blackouts.sum()\n",
    "    print(blackouts_local)\n",
    "\n",
    "    blackouts_total+=blackouts_local\n",
    "\n",
    "    print('Done with year', i)\n",
    "\n",
    "# variable for the time after the script is completed so we can calculate the time the script took to run\n",
    "t2 = tp.time()\n",
    "\n",
    "print('The total time of the script was:',t2-t1, 'seconds')\n",
    "print('The total blackouts from 2014-2022:', blackouts_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdf1900-7c9e-4686-b9a0-54a8a0e99c18",
   "metadata": {},
   "source": [
    "We can see that the script took a total of ~70 seconds to read in the files. Now lets try the same using MPI and multiple processors. In this example, we will use 9 processes each reading in a different file using its own processor all in parallel. To do this, we need to submit a job to Perlmutter using the sbatch script \"eagle_mpi.sbatch\"\n",
    "\n",
    "A batch script is a file used to submit a job to a job scheduler/workload manager like Slurm. The batch script contains details of the job like the job name, max time the job can run, how many nodes are being requested for the job, which account the job should be charged to, etc.\n",
    "\n",
    "Our batch script is very simple and looks like this:\n",
    "\n",
    "```bash\n",
    "#!/bin/bash\n",
    "#SBATCH --constraint=cpu\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --time=10\n",
    "#SBATCH --ntasks-per-node=9\n",
    "#SBATCH --job-name eaglei_mpi-%j\n",
    "#SBATCH -o eaglei_mpi-%j.out\n",
    "#SBATCH -e eaglei_mpi-%j.err\n",
    "\n",
    "cd ~/jupyter_bootcampproject_examples/eaglei_mpi_scripts\n",
    "\n",
    "srun -n9 python3 eaglei_mpi.py\n",
    "```\n",
    "\n",
    "To run it, just execute the next shell which submits our script to Perlmutter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "37fcb6a6-478a-49ab-a813-33d2577c9188",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ID=!sbatch --parsable eaglei_mpi.sbatch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54982107-1516-4999-8912-c2f28da6ccc7",
   "metadata": {},
   "source": [
    "Once you see a new file in your directory to the left, you can open and print it with the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328a54a4-b25e-4bb2-afaf-83689ff89236",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(f\"eaglei_mpi-{ID.n}.out\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d67f25-16e5-4498-abc8-ee2207bf480b",
   "metadata": {},
   "source": [
    "We can see there was quite a speedup from sharing the load of reading in the files using MPI. Lets look at another example, in this example we will use the 2014 EagleI power outage data set to calculate the total number of blackouts for each county."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "83aae52f-df96-45d1-a497-d30928ee3927",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time of script 2.6224021911621094\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS Code</th>\n",
       "      <th>Blackout Sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1037</td>\n",
       "      <td>970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1051</td>\n",
       "      <td>126098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1109</td>\n",
       "      <td>4131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1121</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4017</td>\n",
       "      <td>2848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FIPS Code  Blackout Sum\n",
       "0       1037           970\n",
       "1       1051        126098\n",
       "2       1109          4131\n",
       "3       1121           196\n",
       "4       4017          2848"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time as tp\n",
    "\n",
    "df = pd.read_csv(f'../data/eaglei_outages/eaglei_outages_2014.csv')\n",
    "\n",
    "all_counties = df.fips_code.unique()\n",
    "\n",
    "t1=tp.time()\n",
    "counties = []\n",
    "sums = []\n",
    "\n",
    "for i in all_counties:\n",
    "    #Find the position in the CSV of a specific county (i)\n",
    "    specific_county_filter = df['fips_code'] == i\n",
    "\n",
    "    #Filter out the data so that we only look at a specific county (i)\n",
    "    specific_county_data  = df[specific_county_filter]['sum']\n",
    "\n",
    "    #Add up the total blackouts of a specific county (i)\n",
    "    specific_county_sum = specific_county_data.sum()\n",
    "    \n",
    "    counties.append(int(i))\n",
    "    sums.append(int(specific_county_sum))\n",
    "    \n",
    "\n",
    "d = {'FIPS Code': counties, 'Blackout Sum' : sums}\n",
    "blackouts_df = pd.DataFrame(data=d)  \n",
    "    \n",
    "t2=tp.time()\n",
    "\n",
    "print('Total time of script', t2-t1)\n",
    "blackouts_df.sort_values(by=['FIPS Code'])\n",
    "blackouts_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c938ad99-e5d0-4155-9ff0-f305f93c0e9e",
   "metadata": {},
   "source": [
    "Now, lets try the same thing but lets use MPI to see if we can speed up the calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ac31c83e-7e99-4660-80a3-e3c390dd20d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ID=!sbatch --parsable eaglei_mpi_ex2.sbatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4606dee4-8a2d-4d7a-9bc3-ea63d9269d2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS Code</th>\n",
       "      <th>Blackout Sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1037</td>\n",
       "      <td>970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1051</td>\n",
       "      <td>126098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1109</td>\n",
       "      <td>4131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1121</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4017</td>\n",
       "      <td>2848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FIPS Code  Blackout Sum\n",
       "0       1037           970\n",
       "1       1051        126098\n",
       "2       1109          4131\n",
       "3       1121           196\n",
       "4       4017          2848"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(f\"eaglei_mpi_ex2-{ID.n}.out\") as f:\n",
    "    print(f.read())\n",
    "    \n",
    "blackouts_df = pd.read_csv('county_blackouts.csv')\n",
    "blackouts_df.sort_values(by=['FIPS Code'], ascending=True)\n",
    "blackouts_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5e6e05-f676-45b1-a930-dfe50263e9ff",
   "metadata": {},
   "source": [
    "We used 8 processes in parallel and our total time decreased to ~0.7 seconds. We got a speedup and we are even adding a step to write the file to the filesystem in csv form so we can load it into a pandas dataframe in Jupyter. If we continue to increase the number of parallel processes will see more gains in performance?\n",
    "\n",
    "Try editing the `my_ex2.sbatch` script and running it with the cells below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3ed85e-9762-4115-a092-345b8307af31",
   "metadata": {},
   "outputs": [],
   "source": [
    "ID=!sbatch --parsable my_ex2.sbatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6b74e3ab-161c-4daf-9144-046be803d7f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'my_ex2-12387723.out'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1109144/3897807094.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"my_ex2-{ID.n}.out\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mblackouts_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'county_blackouts.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mblackouts_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'FIPS Code'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'my_ex2-12387723.out'"
     ]
    }
   ],
   "source": [
    "with open(f\"my_ex2-{ID.n}.out\") as f:\n",
    "    print(f.read())\n",
    "    \n",
    "blackouts_df = pd.read_csv('county_blackouts.csv')\n",
    "blackouts_df.sort_values(by=['FIPS Code'], ascending=True)\n",
    "blackouts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f8203e-f622-4779-b5fe-3a8b5e39a386",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NERSC Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
